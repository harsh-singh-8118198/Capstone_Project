{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkceQrA1yjI6",
        "outputId": "8e190f16-442b-4cb1-9a99-4c69f6d79df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.11/dist-packages (3.7.3)\n",
            "Requirement already satisfied: pathway in /usr/local/lib/python3.11/dist-packages (0.24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh) (1.3.2)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.11/dist-packages (from bokeh) (1.45.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.11/dist-packages (from bokeh) (24.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh) (11.2.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh) (2025.4.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.11/dist-packages (from pathway) (3.11.15)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (8.2.1)\n",
            "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.4.1)\n",
            "Requirement already satisfied: h3>=4 in /usr/local/lib/python3.11/dist-packages (from pathway) (4.3.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.6.1)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.1.1)\n",
            "Requirement already satisfied: pyarrow<19.0.0,>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (18.1.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.32.3)\n",
            "Requirement already satisfied: python-sat>=0.1.8.dev0 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.8.dev17)\n",
            "Requirement already satisfied: beartype<0.16.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (0.15.0)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (13.9.4)\n",
            "Requirement already satisfied: diskcache>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (5.6.3)\n",
            "Requirement already satisfied: boto3<1.36.0,>=1.26.76 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.35.93)\n",
            "Requirement already satisfied: aiobotocore==2.17.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.17.0)\n",
            "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.174.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (4.14.0)\n",
            "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.7.2)\n",
            "Requirement already satisfied: jupyter-bokeh>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from pathway) (4.0.5)\n",
            "Requirement already satisfied: jmespath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.0.1)\n",
            "Requirement already satisfied: aiohttp-cors>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (0.8.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (1.34.1)\n",
            "Requirement already satisfied: fs>=2.4.16 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.4.16)\n",
            "Requirement already satisfied: async-lru>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.0.5)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (3.5)\n",
            "Requirement already satisfied: google-cloud-pubsub>=2.21.1 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.30.0)\n",
            "Requirement already satisfied: google-cloud-bigquery~=3.29.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (3.29.0)\n",
            "Requirement already satisfied: pydantic~=2.9.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (2.9.2)\n",
            "Requirement already satisfied: gitpython>=3.1.43 in /usr/local/lib/python3.11/dist-packages (from pathway) (3.1.44)\n",
            "Requirement already satisfied: deltalake<0.18.0,>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from pathway) (0.17.4)\n",
            "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from aiobotocore==2.17.0->pathway) (0.12.0)\n",
            "Requirement already satisfied: botocore<1.35.94,>=1.35.74 in /usr/local/lib/python3.11/dist-packages (from aiobotocore==2.17.0->pathway) (1.35.93)\n",
            "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from aiobotocore==2.17.0->pathway) (6.6.3)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from aiobotocore==2.17.0->pathway) (2.4.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.11/dist-packages (from aiobotocore==2.17.0->pathway) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (1.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->pathway) (1.20.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from boto3<1.36.0,>=1.26.76->pathway) (0.10.4)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from deltalake<0.18.0,>=0.17.0->pathway) (0.7)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.11/dist-packages (from fs>=2.4.16->pathway) (1.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from fs>=2.4.16->pathway) (75.2.0)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.11/dist-packages (from fs>=2.4.16->pathway) (1.17.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy>=2.4.0->pathway) (2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.43->pathway) (4.0.12)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=2.108.0->pathway) (4.2.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery~=3.29.0->pathway) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery~=3.29.0->pathway) (2.7.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.51.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.73.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (5.29.5)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (0.14.2)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.71.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh) (3.0.2)\n",
            "Requirement already satisfied: ipywidgets==8.* in /usr/local/lib/python3.11/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (8.1.7)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.15)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.22.0->pathway) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.34.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.22.0->pathway) (0.55b1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (3.8.2)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (0.4.2)\n",
            "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (2.2.1)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (3.0.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from panel>=1.3.1->pathway) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.9.0->pathway) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.9.0->pathway) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->pathway) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->pathway) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->pathway) (2025.6.15)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->pathway) (2.19.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->pathway) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->pathway) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->pathway) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.43->pathway) (5.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (4.9.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-resumable-media<3.0dev,>=2.0.0->google-cloud-bigquery~=3.29.0->pathway) (1.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=2.108.0->pathway) (3.2.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.22.0->pathway) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py->panel>=1.3.1->pathway) (0.1.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel>=1.3.1->pathway) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel>=1.3.1->pathway) (1.0.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.9.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.13)\n",
            "Starting simulation for Model 3...\n",
            "Renamed column 'ID' to 'Parking Space ID'.\n",
            "Renamed column 'LastUpdatedDate' to 'Date'.\n",
            "Renamed column 'LastUpdatedTime' to 'Time'.\n",
            "Renamed column 'VehicleType' to 'Type of incoming vehicle'.\n",
            "Renamed column 'TrafficConditionNearby' to 'Nearby traffic congestion level'.\n",
            "Renamed column 'QueueLength' to 'Queue length'.\n",
            "Renamed column 'IsSpecialDay' to 'Special day indicator'.\n",
            "Warning: 'Time Point' column not found.\n",
            "Combining 'Date' and 'Time' to create a full timestamp for sorting.\n"
          ]
        }
      ],
      "source": [
        "# --- 0. Environment Setup and Library Imports ---\n",
        "# Run these commands in your Google Colab notebook to install necessary libraries.\n",
        "!pip install pandas numpy bokeh pathway # Pathway is included for conceptual understanding, but not fully utilized in the direct runnable simulation here.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathway as pw # Imported for conceptual explanation, not directly used in the runnable simulation loop.\n",
        "from bokeh.plotting import figure, show, ColumnDataSource\n",
        "from bokeh.io import output_notebook, push_notebook\n",
        "import time\n",
        "from math import radians, sin, cos, sqrt, atan2\n",
        "\n",
        "# --- 1. Global Constants and Parameters ---\n",
        "\n",
        "# Base price for parking\n",
        "BASE_PRICE = 10.0\n",
        "\n",
        "# Model 1: Baseline Linear Model parameters\n",
        "# Price_t+1 = Price_t + alpha * (Occupancy / Capacity)\n",
        "ALPHA_MODEL1 = 0.5\n",
        "\n",
        "# Model 2: Demand-Based Price Function parameters\n",
        "# Price = Base Price * (1 + lambda * NormalizedDemand)\n",
        "LAMBDA_MODEL2 = 5.0\n",
        "\n",
        "# Weights for Demand Function (Model 2) - these are example values, tune as needed\n",
        "# These weights determine the influence of each factor on demand.\n",
        "WEIGHT_OCCUPANCY_RATE = 0.6\n",
        "WEIGHT_QUEUE_LENGTH = 0.2\n",
        "WEIGHT_TRAFFIC = 0.1\n",
        "WEIGHT_SPECIAL_DAY = 0.1\n",
        "WEIGHT_VEHICLE_TYPE_CAR = 0.05\n",
        "WEIGHT_VEHICLE_TYPE_BIKE = 0.02\n",
        "WEIGHT_VEHICLE_TYPE_TRUCK = 0.03\n",
        "\n",
        "# Price bounds for Model 2 and 3 to ensure smooth and bounded price variations\n",
        "MIN_PRICE_FACTOR = 0.5 # Minimum price will be BASE_PRICE * MIN_PRICE_FACTOR\n",
        "MAX_PRICE_FACTOR = 2.0 # Maximum price will be BASE_PRICE * MAX_PRICE_FACTOR\n",
        "\n",
        "# --- 2. Helper Functions ---\n",
        "\n",
        "def calculate_distance(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calculate the distance between two points on Earth using the Haversine formula.\n",
        "    Returns distance in kilometers.\n",
        "    \"\"\"\n",
        "    R = 6371 # Radius of Earth in kilometers\n",
        "\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
        "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# --- 3. Pricing Models Implementations ---\n",
        "\n",
        "def model1_pricing_logic(df_batch):\n",
        "    \"\"\"\n",
        "    Model 1: Baseline Linear Model\n",
        "    Price_t+1 = Price_t + alpha * (Occupancy / Capacity)\n",
        "\n",
        "    Args:\n",
        "        df_batch (pd.DataFrame): A DataFrame containing a batch of data for parking spaces.\n",
        "                                 Must include 'Occupancy', 'Capacity', and 'previous_price'.\n",
        "                                 'previous_price' is initialized to BASE_PRICE if not present.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with 'predicted_price' added.\n",
        "    \"\"\"\n",
        "    # Ensure 'previous_price' column exists for calculations.\n",
        "    # In a true streaming Pathway app, this would be managed by stateful transforms.\n",
        "    if 'previous_price' not in df_batch.columns:\n",
        "        df_batch['previous_price'] = BASE_PRICE\n",
        "\n",
        "    # Calculate occupancy rate\n",
        "    df_batch['occupancy_rate'] = df_batch['Occupancy'] / df_batch['Capacity']\n",
        "    # Apply the linear pricing formula\n",
        "    df_batch['predicted_price'] = df_batch['previous_price'] + ALPHA_MODEL1 * df_batch['occupancy_rate']\n",
        "    # Clip prices to ensure they stay within defined bounds\n",
        "    df_batch['predicted_price'] = np.clip(df_batch['predicted_price'], BASE_PRICE * MIN_PRICE_FACTOR, BASE_PRICE * MAX_PRICE_FACTOR)\n",
        "    return df_batch\n",
        "\n",
        "def calculate_demand(row):\n",
        "    \"\"\"\n",
        "    Calculates a demand score based on various features. Used in Model 2.\n",
        "\n",
        "    Args:\n",
        "        row (pd.Series): A single row of parking data.\n",
        "\n",
        "    Returns:\n",
        "        float: The calculated demand score.\n",
        "    \"\"\"\n",
        "    # Ensure all required columns are present before calculation\n",
        "    required_cols = ['Occupancy', 'Capacity', 'Queue length', 'Nearby traffic congestion level',\n",
        "                     'Special day indicator', 'Type of incoming vehicle']\n",
        "    for col in required_cols:\n",
        "        if col not in row.index:\n",
        "            # Handle missing columns gracefully, e.g., by assigning a default value or skipping\n",
        "            print(f\"Warning: Column '{col}' not found in row. Using default value 0 for demand calculation.\")\n",
        "            if col in ['Occupancy', 'Queue length', 'Nearby traffic congestion level']:\n",
        "                row[col] = 0\n",
        "            elif col == 'Capacity':\n",
        "                row[col] = 1 # Avoid division by zero\n",
        "            elif col == 'Special day indicator':\n",
        "                row[col] = 0\n",
        "            elif col == 'Type of incoming vehicle':\n",
        "                row[col] = 'car' # Default to 'car'\n",
        "\n",
        "    occupancy_rate = row['Occupancy'] / row['Capacity']\n",
        "    # Normalize queue length and traffic using tanh for smoother scaling\n",
        "    queue_length_normalized = np.tanh(row['Queue length'] / 10.0) # Assuming max queue length around 10-20\n",
        "    traffic_normalized = np.tanh(row['Nearby traffic congestion level'] / 5.0) # Assuming traffic on a scale, e.g., 0-5\n",
        "\n",
        "    # Convert 'Special day indicator' to a numeric value (0 or 1)\n",
        "    is_special_day = 1 if str(row['Special day indicator']).lower() in ['yes', '1', 'true'] else 0\n",
        "\n",
        "    # Assign weight based on vehicle type\n",
        "    vehicle_type_weight = 0\n",
        "    vehicle_type = str(row['Type of incoming vehicle']).lower()\n",
        "    if vehicle_type == 'car':\n",
        "        vehicle_type_weight = WEIGHT_VEHICLE_TYPE_CAR\n",
        "    elif vehicle_type == 'bike':\n",
        "        vehicle_type_weight = WEIGHT_VEHICLE_TYPE_BIKE\n",
        "    elif vehicle_type == 'truck':\n",
        "        vehicle_type_weight = WEIGHT_VEHICLE_TYPE_TRUCK\n",
        "    # Add 'cycle' as a vehicle type if it exists in the dataset\n",
        "    elif vehicle_type == 'cycle':\n",
        "        vehicle_type_weight = WEIGHT_VEHICLE_TYPE_BIKE # Treating cycles like bikes for now, adjust if needed\n",
        "\n",
        "    # Combine weighted features to get the total demand score\n",
        "    demand = (WEIGHT_OCCUPANCY_RATE * occupancy_rate +\n",
        "              WEIGHT_QUEUE_LENGTH * queue_length_normalized +\n",
        "              WEIGHT_TRAFFIC * traffic_normalized +\n",
        "              WEIGHT_SPECIAL_DAY * is_special_day +\n",
        "              vehicle_type_weight)\n",
        "    return demand\n",
        "\n",
        "def normalize_demand(demand_series):\n",
        "    \"\"\"\n",
        "    Normalizes a Pandas Series of demand values to a 0-1 range.\n",
        "\n",
        "    Args:\n",
        "        demand_series (pd.Series): A Series of demand scores.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: The normalized demand scores.\n",
        "    \"\"\"\n",
        "    min_demand = demand_series.min()\n",
        "    max_demand = demand_series.max()\n",
        "    if max_demand == min_demand:\n",
        "        # If all demand values are the same, return 0.5 to avoid division by zero\n",
        "        return pd.Series([0.5] * len(demand_series), index=demand_series.index)\n",
        "    normalized_demand = (demand_series - min_demand) / (max_demand - min_demand)\n",
        "    return normalized_demand\n",
        "\n",
        "def model2_pricing_logic(df_batch):\n",
        "    \"\"\"\n",
        "    Model 2: Demand-Based Price Function\n",
        "    Price = Base Price * (1 + lambda * NormalizedDemand)\n",
        "\n",
        "    Args:\n",
        "        df_batch (pd.DataFrame): A DataFrame containing a batch of data for parking spaces.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with 'demand', 'normalized_demand', and 'predicted_price' added.\n",
        "    \"\"\"\n",
        "    # Calculate demand for each row in the batch\n",
        "    df_batch['demand'] = df_batch.apply(calculate_demand, axis=1)\n",
        "    # Normalize the calculated demand across the current batch\n",
        "    df_batch['normalized_demand'] = normalize_demand(df_batch['demand'])\n",
        "    # Apply the demand-based pricing formula\n",
        "    df_batch['predicted_price'] = BASE_PRICE * (1 + LAMBDA_MODEL2 * df_batch['normalized_demand'])\n",
        "    # Clip prices to ensure they stay within defined bounds\n",
        "    df_batch['predicted_price'] = np.clip(df_batch['predicted_price'], BASE_PRICE * MIN_PRICE_FACTOR, BASE_PRICE * MAX_PRICE_FACTOR)\n",
        "    return df_batch\n",
        "\n",
        "def model3_pricing_logic(df_batch, all_parking_data_at_timestep):\n",
        "    \"\"\"\n",
        "    Model 3: Competitive Pricing Model\n",
        "    Factors in competitor prices based on proximity.\n",
        "\n",
        "    Args:\n",
        "        df_batch (pd.DataFrame): A DataFrame containing the current batch of data for parking spaces,\n",
        "                                 which should already have 'predicted_price' from Model 2.\n",
        "        all_parking_data_at_timestep (pd.DataFrame): A DataFrame containing data (including prices and locations)\n",
        "                                                     for ALL parking spaces at the current time step.\n",
        "                                                     This is crucial for competitive analysis.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with 'competitive_factor' and adjusted 'predicted_price' added.\n",
        "    \"\"\"\n",
        "    df_batch['competitive_factor'] = 0.0 # Initialize competitive factor\n",
        "\n",
        "    for index, row in df_batch.iterrows():\n",
        "        # Ensure Latitude and Longitude exist\n",
        "        if 'Latitude' not in row or 'Longitude' not in row:\n",
        "            print(f\"Warning: Latitude or Longitude missing for Parking Space ID {row.get('Parking Space ID', 'Unknown')}. Skipping competitive pricing for this entry.\")\n",
        "            continue\n",
        "\n",
        "        current_lat = row['Latitude']\n",
        "        current_lon = row['Longitude']\n",
        "        current_parking_id = row['Parking Space ID']\n",
        "\n",
        "        nearby_competitors_prices = []\n",
        "        # Iterate through all parking spaces at this time step to find competitors\n",
        "        for _, comp_row in all_parking_data_at_timestep.iterrows():\n",
        "            if comp_row['Parking Space ID'] != current_parking_id: # Don't compare with self\n",
        "                # Ensure Latitude and Longitude exist for competitor\n",
        "                if 'Latitude' not in comp_row or 'Longitude' not in comp_row:\n",
        "                    continue # Skip this competitor if location data is missing\n",
        "\n",
        "                comp_lat = comp_row['Latitude']\n",
        "                comp_lon = comp_row['Longitude']\n",
        "                distance = calculate_distance(current_lat, current_lon, comp_lat, comp_lon)\n",
        "\n",
        "                # Consider competitors within a certain radius (e.g., 1 kilometer)\n",
        "                if distance < 1.0: # This radius can be tuned\n",
        "                    # Ensure competitor has a predicted price (from Model 2 or previous step)\n",
        "                    if 'predicted_price' in comp_row:\n",
        "                        nearby_competitors_prices.append(comp_row['predicted_price'])\n",
        "\n",
        "        if nearby_competitors_prices:\n",
        "            avg_competitor_price = np.mean(nearby_competitors_prices)\n",
        "            current_occupancy_rate = row['Occupancy'] / row['Capacity']\n",
        "\n",
        "            # Simple competitive logic:\n",
        "            # 1. If our lot is highly occupied (e.g., >90%) AND nearby competitors are cheaper,\n",
        "            #    consider slightly reducing our price to encourage flow or avoid overpricing.\n",
        "            if current_occupancy_rate > 0.9 and avg_competitor_price < row['predicted_price']:\n",
        "                df_batch.loc[index, 'competitive_factor'] = -0.05 # Reduce price by 5%\n",
        "            # 2. If nearby competitors are significantly more expensive (e.g., 10% higher),\n",
        "            #    we can slightly increase our price while remaining attractive.\n",
        "            elif avg_competitor_price > row['predicted_price'] * 1.1:\n",
        "                df_batch.loc[index, 'competitive_factor'] = 0.03 # Increase price by 3%\n",
        "\n",
        "    # Apply the competitive factor to the predicted price\n",
        "    df_batch['predicted_price'] = df_batch['predicted_price'] * (1 + df_batch['competitive_factor'])\n",
        "    # Clip prices again after competitive adjustment\n",
        "    df_batch['predicted_price'] = np.clip(df_batch['predicted_price'], BASE_PRICE * MIN_PRICE_FACTOR, BASE_PRICE * MAX_PRICE_FACTOR)\n",
        "    return df_batch\n",
        "\n",
        "def apply_pricing_model(df_batch, current_model_choice, all_parking_data_at_timestep):\n",
        "    \"\"\"\n",
        "    Applies the chosen pricing model to a batch of incoming data.\n",
        "\n",
        "    Args:\n",
        "        df_batch (pd.DataFrame): The current batch of streaming data.\n",
        "        current_model_choice (int): The ID of the model to use (1, 2, or 3).\n",
        "        all_parking_data_at_timestep (pd.DataFrame): Snapshot of all parking data at the current time step.\n",
        "                                                     Required for Model 3.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with 'predicted_price' based on the chosen model.\n",
        "    \"\"\"\n",
        "    if current_model_choice == 1:\n",
        "        return model1_pricing_logic(df_batch.copy())\n",
        "    elif current_model_choice == 2:\n",
        "        return model2_pricing_logic(df_batch.copy())\n",
        "    elif current_model_choice == 3:\n",
        "        # For Model 3, first apply Model 2 to get a base price, then apply competitive logic\n",
        "        df_with_model2_prices = model2_pricing_logic(df_batch.copy())\n",
        "        return model3_pricing_logic(df_with_model2_prices, all_parking_data_at_timestep)\n",
        "    else:\n",
        "        # Default to base price if no valid model is chosen\n",
        "        df_batch['predicted_price'] = BASE_PRICE\n",
        "        return df_batch\n",
        "\n",
        "# --- 4. Real-time Simulation Loop with Bokeh Visualization ---\n",
        "\n",
        "def run_simulation(data_path, selected_model):\n",
        "    \"\"\"\n",
        "    Simulates real-time data streaming and applies the dynamic pricing model,\n",
        "    visualizing results with Bokeh.\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the dataset CSV file.\n",
        "        selected_model (int): The pricing model to use (1, 2, or 3).\n",
        "    \"\"\"\n",
        "    print(f\"Starting simulation for Model {selected_model}...\")\n",
        "\n",
        "    # Load the entire dataset. We will simulate streaming by processing it time-step by time-step.\n",
        "    full_data = pd.read_csv(data_path)\n",
        "\n",
        "    # --- Robust Column Name Handling ---\n",
        "    # Define a mapping from potential CSV column names to expected column names in the code\n",
        "    column_name_mapping = {\n",
        "        'id': 'Parking Space ID',\n",
        "        'systemcodenumber': 'Parking Space ID', # Assuming SystemCodeNumber can also serve as ID if 'ID' is missing\n",
        "        'lastupdateddate': 'Date',\n",
        "        'lastupdatedtime': 'Time', # Will be combined with Date or used to infer Time Point\n",
        "        'vehicletype': 'Type of incoming vehicle',\n",
        "        'trafficconditionnearby': 'Nearby traffic congestion level',\n",
        "        'queuelength': 'Queue length',\n",
        "        'isspecialday': 'Special day indicator',\n",
        "        'capacity': 'Capacity',\n",
        "        'occupancy': 'Occupancy',\n",
        "        'latitude': 'Latitude',\n",
        "        'longitude': 'Longitude'\n",
        "    }\n",
        "\n",
        "    # Standardize column names\n",
        "    current_columns = {col.lower(): col for col in full_data.columns}\n",
        "    for old_name_lower, new_name in column_name_mapping.items():\n",
        "        if new_name not in full_data.columns: # Only rename if the target column name doesn't already exist\n",
        "            if old_name_lower in current_columns:\n",
        "                original_col_name = current_columns[old_name_lower]\n",
        "                full_data.rename(columns={original_col_name: new_name}, inplace=True)\n",
        "                print(f\"Renamed column '{original_col_name}' to '{new_name}'.\")\n",
        "\n",
        "    # Final check for critical columns after renaming\n",
        "    critical_columns = ['Parking Space ID', 'Capacity', 'Occupancy', 'Latitude', 'Longitude',\n",
        "                        'Type of incoming vehicle', 'Nearby traffic congestion level', 'Queue length',\n",
        "                        'Special day indicator'] # Corrected: 'TrafficConditionNearby' to 'Nearby traffic congestion level'\n",
        "    for col in critical_columns:\n",
        "        if col not in full_data.columns:\n",
        "            print(f\"Error: Critical column '{col}' not found in the dataset after renaming attempts. Available columns: {full_data.columns.tolist()}\")\n",
        "            raise KeyError(f\"Critical column '{col}' is missing or named differently in dataset.csv. Please ensure it exists.\")\n",
        "\n",
        "\n",
        "    # Ensure 'Time Point' is correctly identified for plotting\n",
        "    # If 'Time Point' column is missing, create it based on cumulative count per parking space.\n",
        "    # If 'Time' (LastUpdatedTime) exists, combine with 'Date' to create a proper datetime for sorting.\n",
        "    if 'Time Point' not in full_data.columns:\n",
        "        print(\"Warning: 'Time Point' column not found.\")\n",
        "        if 'Date' in full_data.columns and 'Time' in full_data.columns:\n",
        "            print(\"Combining 'Date' and 'Time' to create a full timestamp for sorting.\")\n",
        "            # Combine 'Date' and 'Time' into a single datetime column for accurate sorting\n",
        "            full_data['FullTimestamp'] = pd.to_datetime(full_data['Date'] + ' ' + full_data['Time'], errors='coerce', dayfirst=True)\n",
        "            full_data.sort_values(by=['Parking Space ID', 'FullTimestamp'], inplace=True)\n",
        "            full_data.dropna(subset=['FullTimestamp'], inplace=True)\n",
        "            # Create 'Time Point' as a sequential integer for plotting within each parking space's daily data\n",
        "            full_data['Time Point'] = full_data.groupby(['Parking Space ID', full_data['FullTimestamp'].dt.date]).cumcount() + 1\n",
        "        else:\n",
        "            print(\"Generating 'Time Point' based on cumulative count per parking space (less precise without full timestamp).\")\n",
        "            full_data['Time Point'] = full_data.groupby('Parking Space ID').cumcount() + 1\n",
        "    else:\n",
        "        # Ensure 'Time Point' is numeric, if it exists\n",
        "        full_data['Time Point'] = pd.to_numeric(full_data['Time Point'], errors='coerce')\n",
        "        full_data.dropna(subset=['Time Point'], inplace=True) # Drop rows where Time Point couldn't be converted\n",
        "\n",
        "    # Convert 'Date' column to datetime objects if it exists after renaming\n",
        "    if 'Date' in full_data.columns:\n",
        "        full_data['Date'] = pd.to_datetime(full_data['Date'], errors='coerce', dayfirst=True) # Use dayfirst for DD-MM-YYYY format\n",
        "        full_data.dropna(subset=['Date'], inplace=True) # Drop rows where Date couldn't be converted\n",
        "\n",
        "\n",
        "    # Get unique parking space IDs for setting up Bokeh plots\n",
        "    parking_space_ids = sorted(full_data['Parking Space ID'].unique())\n",
        "\n",
        "    # Initialize previous_price for all parking spaces for Model 1's state management.\n",
        "    # This dictionary will hold the last predicted price for each parking space.\n",
        "    parking_space_state = {pid: {'previous_price': BASE_PRICE} for pid in parking_space_ids}\n",
        "\n",
        "    # --- Bokeh Visualization Setup ---\n",
        "    output_notebook() # Directs Bokeh to render plots in the Jupyter/Colab notebook output\n",
        "\n",
        "    # Create the main Bokeh figure\n",
        "    p = figure(\n",
        "        x_axis_label=\"Time Point (Simulated)\",\n",
        "        y_axis_label=\"Predicted Price ($)\",\n",
        "        title=f\"Real-time Parking Price Prediction (Model {selected_model})\",\n",
        "        height=500,\n",
        "        width=900,\n",
        "        x_range=(0, full_data['Time Point'].max() + 1), # X-axis range based on max time point\n",
        "        y_range=(BASE_PRICE * MIN_PRICE_FACTOR * 0.9, BASE_PRICE * MAX_PRICE_FACTOR * 1.1) # Y-axis with buffer\n",
        "    )\n",
        "\n",
        "    # Dictionary to hold ColumnDataSource for each parking space.\n",
        "    # Each line on the plot will have its own data source.\n",
        "    parking_sources = {}\n",
        "    # Define a color palette for the lines\n",
        "    colors = [\"#e6194b\", \"#3cb44b\", \"#ffe119\", \"#4363d8\", \"#f58231\", \"#911eb4\", \"#46f0f0\", \"#f032e6\",\n",
        "              \"#bcf60c\", \"#fabebe\", \"#008080\", \"#e6beff\", \"#9a6324\", \"#fffac8\"]\n",
        "\n",
        "    # Initialize a line glyph and ColumnDataSource for each parking space\n",
        "    for i, pid in enumerate(parking_space_ids):\n",
        "        parking_sources[pid] = ColumnDataSource(data={'time': [], 'price': []})\n",
        "        p.line(\n",
        "            x='time', y='price',\n",
        "            legend_label=f\"Parking {pid}\",\n",
        "            line_width=2,\n",
        "            color=colors[i % len(colors)], # Assign a color from the palette\n",
        "            source=parking_sources[pid] # Link the line to its specific data source\n",
        "        )\n",
        "\n",
        "    p.legend.location = \"top_left\"\n",
        "    p.legend.click_policy=\"hide\" # Allows users to hide/show individual lines by clicking their legend entry\n",
        "\n",
        "    # Show the plot initially to get the handle for updates\n",
        "    # `notebook_handle=True` is crucial for `push_notebook` to work\n",
        "    handle = show(p, notebook_handle=True)\n",
        "\n",
        "    # --- Simulate Streaming Data and Update Plot ---\n",
        "    # Determine how to iterate through data: by 'Date' and 'Time Point' or just 'Time Point'\n",
        "    if 'Date' in full_data.columns and 'FullTimestamp' in full_data.columns:\n",
        "        # Sort by full timestamp to ensure correct chronological order across all parking spaces\n",
        "        full_data.sort_values(by='FullTimestamp', inplace=True)\n",
        "        # Iterate through unique timestamps to process all parking spaces at that moment\n",
        "        unique_timestamps = sorted(full_data['FullTimestamp'].unique())\n",
        "        time_iteration_column = 'FullTimestamp'\n",
        "    else:\n",
        "        # Fallback to 'Time Point' if full timestamp isn't available or preferred for iteration\n",
        "        full_data.sort_values(by=['Parking Space ID', 'Time Point'], inplace=True)\n",
        "        unique_timestamps = sorted(full_data['Time Point'].unique())\n",
        "        time_iteration_column = 'Time Point'\n",
        "\n",
        "\n",
        "    for current_timestamp_value in unique_timestamps:\n",
        "        current_time_data = full_data[full_data[time_iteration_column] == current_timestamp_value].copy()\n",
        "\n",
        "        # For Model 1, update the 'previous_price' column in the current batch\n",
        "        # based on the state from the previous time step.\n",
        "        if selected_model == 1:\n",
        "            for pid in current_time_data['Parking Space ID'].unique():\n",
        "                current_time_data.loc[current_time_data['Parking Space ID'] == pid, 'previous_price'] = \\\n",
        "                    parking_space_state[pid]['previous_price']\n",
        "\n",
        "        # Apply the selected pricing model to the current batch of data.\n",
        "        # For Model 3, pass the entire `current_time_data` as `all_parking_data_at_timestep`\n",
        "        # to allow competitive analysis across all parking spaces at this moment.\n",
        "        processed_data = apply_pricing_model(current_time_data, selected_model, current_time_data.copy())\n",
        "\n",
        "        # Update the state (previous price) for Model 1 for the next iteration\n",
        "        if selected_model == 1:\n",
        "            for pid in processed_data['Parking Space ID'].unique():\n",
        "                # Ensure the parking space exists in the processed data before updating state\n",
        "                if not processed_data[processed_data['Parking Space ID'] == pid].empty:\n",
        "                    parking_space_state[pid]['previous_price'] = \\\n",
        "                        processed_data.loc[processed_data['Parking Space ID'] == pid, 'predicted_price'].iloc[0]\n",
        "\n",
        "        # Update Bokeh ColumnDataSource for each parking space\n",
        "        for pid in parking_space_ids:\n",
        "            # Get the row corresponding to the current parking space at the current time point\n",
        "            parking_row = processed_data[processed_data['Parking Space ID'] == pid]\n",
        "            if not parking_row.empty:\n",
        "                # Use 'Time Point' for plotting X-axis regardless of internal iteration method\n",
        "                new_time = [parking_row['Time Point'].iloc[0]]\n",
        "                new_price = [parking_row['predicted_price'].iloc[0]]\n",
        "                # Stream the new data point to the respective ColumnDataSource\n",
        "                parking_sources[pid].stream({'time': new_time, 'price': new_price})\n",
        "\n",
        "        # Push the updated plot to the notebook output\n",
        "        push_notebook(handle=handle)\n",
        "        time.sleep(0.05) # Simulate a small delay for real-time effect (adjust as needed)\n",
        "\n",
        "    print(f\"\\nSimulation for Model {selected_model} completed for all data points.\")\n",
        "    print(\"Final predicted prices for the last time point:\")\n",
        "    # Display the final predicted prices for all parking spaces from the last processed batch\n",
        "    print(processed_data[['Parking Space ID', 'predicted_price']])\n",
        "\n",
        "# --- 5. Conceptual Pathway Integration (for reference) ---\n",
        "# This section outlines how Pathway would be used for a true real-time application.\n",
        "# The runnable code above simulates this behavior using Pandas and Bokeh directly.\n",
        "\n",
        "# @pw.udf\n",
        "# def pathway_model1_udf(row, state):\n",
        "#     # This UDF would be applied to each incoming row in a Pathway stream.\n",
        "#     # 'state' would manage the 'previous_price' for each parking space.\n",
        "#     # This is a highly simplified representation.\n",
        "#     occupancy_rate = row.Occupancy / row.Capacity\n",
        "#     previous_price = state.get('price', BASE_PRICE) # Get previous price from state\n",
        "#     predicted_price = previous_price + ALPHA_MODEL1 * occupancy_rate\n",
        "#     predicted_price = np.clip(predicted_price, BASE_PRICE * MIN_PRICE_FACTOR, BASE_PRICE * MAX_PRICE_FACTOR)\n",
        "#     state['price'] = predicted_price # Update state for next iteration\n",
        "#     return {'Parking Space ID': row['Parking Space ID'], 'predicted_price': predicted_price, 'time_point': row['Time Point']}\n",
        "\n",
        "# def run_pathway_app(data_path, selected_model):\n",
        "#     # Initialize Pathway context\n",
        "#     # pw.set_debug_mode(True) # Optional: for debugging Pathway tables\n",
        "\n",
        "#     # 1. Data Ingestion: Read CSV as a streaming table\n",
        "#     # This simulates new data arriving over time.\n",
        "#     input_stream = pw.io.csv.read(\n",
        "#         data_path,\n",
        "#         schema=None, # Pathway can infer schema\n",
        "#         mode=\"streaming\",\n",
        "#         autocommit_duration_ms=100 # Simulate small batches arriving every 100ms\n",
        "#     )\n",
        "\n",
        "#     # 2. Feature Engineering and Model Application\n",
        "#     # For Model 1 (stateful):\n",
        "#     if selected_model == 1:\n",
        "#         # Use a stateful transform to carry 'previous_price' for each parking space.\n",
        "#         # This would involve `pw.state.min_state` or a custom stateful UDF.\n",
        "#         # Example (conceptual, requires proper state management in UDF):\n",
        "#         # predicted_prices = input_stream.group_by(input_stream.Parking_Space_ID).map(\n",
        "#         #     lambda row, state: pathway_model1_udf(row, state)\n",
        "#         # )\n",
        "#         pass # Placeholder for actual Pathway stateful logic\n",
        "\n",
        "#     # For Model 2 (stateless per row, but needs batch-level normalization):\n",
        "#     elif selected_model == 2:\n",
        "#         # This would involve `pw.map` for `calculate_demand`\n",
        "#         # and then a `pw.reduce` or another `pw.map` with a global view for `normalize_demand`.\n",
        "#         # This is more complex in Pathway than a simple row-wise map.\n",
        "#         pass # Placeholder for actual Pathway logic\n",
        "\n",
        "#     # For Model 3 (needs joins for competitive data):\n",
        "#     elif selected_model == 3:\n",
        "#         # This would involve joining the input_stream with itself or another table\n",
        "#         # representing the current state of all parking lots, based on proximity.\n",
        "#         pass # Placeholder for actual Pathway join logic\n",
        "\n",
        "#     # 3. Output and Visualization\n",
        "#     # Output the predicted prices to a file or a visualization sink.\n",
        "#     # For Bokeh, Pathway has `pw.io.bokeh.write` but it usually requires a running Bokeh server.\n",
        "#     # predicted_prices.write(pw.io.csv.write(\"predicted_prices_pathway.csv\"))\n",
        "\n",
        "#     # Start the Pathway data processing engine (this is blocking)\n",
        "#     # pw.run()\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the path to your dataset.csv file\n",
        "    # Make sure this file is uploaded to your Colab environment or accessible.\n",
        "    DATASET_PATH = '/content/dataset.csv'\n",
        "\n",
        "    # Choose which model to run (1, 2, or 3)\n",
        "    # model_to_run = 1 # Uncomment to run Model 1\n",
        "    # model_to_run = 2 # Uncomment to run Model 2\n",
        "    model_to_run = 3 # Uncomment to run Model 3 (Recommended for full features)\n",
        "\n",
        "    run_simulation(DATASET_PATH, model_to_run)\n",
        "\n",
        "    # You can also conceptually call the Pathway function here if you had a complete Pathway setup:\n",
        "    # print(\"\\nConceptual Pathway execution (requires full Pathway setup and specific UDFs):\")\n",
        "    # run_pathway_app(DATASET_PATH, model_to_run)\n"
      ]
    }
  ]
}