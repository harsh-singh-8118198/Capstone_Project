{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- 0. Environment Setup and Library Imports ---\n",
        "# Run these commands in your Google Colab notebook to install necessary libraries.\n",
        "!pip install pandas numpy bokeh pathway # Pathway is included for conceptual understanding, but not fully utilized in the direct runnable simulation here.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathway as pw # Imported for conceptual explanation, not directly used in the runnable simulation loop.\n",
        "from bokeh.plotting import figure, show, ColumnDataSource\n",
        "from bokeh.io import output_notebook, push_notebook\n",
        "import time\n",
        "from math import radians, sin, cos, sqrt, atan2\n",
        "\n",
        "# --- 1. Global Constants and Parameters ---\n",
        "\n",
        "# Base price for parking\n",
        "BASE_PRICE = 10.0\n",
        "\n",
        "# Model 1: Baseline Linear Model parameters\n",
        "# Price_t+1 = Price_t + alpha * (Occupancy / Capacity)\n",
        "ALPHA_MODEL1 = 0.5\n",
        "\n",
        "# Model 2: Demand-Based Price Function parameters\n",
        "# Price = Base Price * (1 + lambda * NormalizedDemand)\n",
        "LAMBDA_MODEL2 = 5.0\n",
        "\n",
        "# Weights for Demand Function (Model 2) - these are example values, tune as needed\n",
        "# These weights determine the influence of each factor on demand.\n",
        "WEIGHT_OCCUPANCY_RATE = 0.6\n",
        "WEIGHT_QUEUE_LENGTH = 0.2\n",
        "WEIGHT_TRAFFIC = 0.1\n",
        "WEIGHT_SPECIAL_DAY = 0.1\n",
        "WEIGHT_VEHICLE_TYPE_CAR = 0.05\n",
        "WEIGHT_VEHICLE_TYPE_BIKE = 0.02\n",
        "WEIGHT_VEHICLE_TYPE_TRUCK = 0.03\n",
        "\n",
        "# Price bounds for Model 2 and 3 to ensure smooth and bounded price variations\n",
        "MIN_PRICE_FACTOR = 0.5 # Minimum price will be BASE_PRICE * MIN_PRICE_FACTOR\n",
        "MAX_PRICE_FACTOR = 2.0 # Maximum price will be BASE_PRICE * MAX_PRICE_FACTOR\n",
        "\n",
        "# --- 2. Helper Functions ---\n",
        "\n",
        "def calculate_distance(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calculate the distance between two points on Earth using the Haversine formula.\n",
        "    Returns distance in kilometers.\n",
        "    \"\"\"\n",
        "    R = 6371 # Radius of Earth in kilometers\n",
        "\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
        "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# --- 3. Pricing Models Implementations ---\n",
        "\n",
        "def model1_pricing_logic(df_batch):\n",
        "    \"\"\"\n",
        "    Model 1: Baseline Linear Model\n",
        "    Price_t+1 = Price_t + alpha * (Occupancy / Capacity)\n",
        "\n",
        "    Args:\n",
        "        df_batch (pd.DataFrame): A DataFrame containing a batch of data for parking spaces.\n",
        "                                 Must include 'Occupancy', 'Capacity', and 'previous_price'.\n",
        "                                 'previous_price' is initialized to BASE_PRICE if not present.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with 'predicted_price' added.\n",
        "    \"\"\"\n",
        "    # Ensure 'previous_price' column exists for calculations.\n",
        "    # In a true streaming Pathway app, this would be managed by stateful transforms.\n",
        "    if 'previous_price' not in df_batch.columns:\n",
        "        df_batch['previous_price'] = BASE_PRICE\n",
        "\n",
        "    # Calculate occupancy rate\n",
        "    df_batch['occupancy_rate'] = df_batch['Occupancy'] / df_batch['Capacity']\n",
        "    # Apply the linear pricing formula\n",
        "    df_batch['predicted_price'] = df_batch['previous_price'] + ALPHA_MODEL1 * df_batch['occupancy_rate']\n",
        "    # Clip prices to ensure they stay within defined bounds\n",
        "    df_batch['predicted_price'] = np.clip(df_batch['predicted_price'], BASE_PRICE * MIN_PRICE_FACTOR, BASE_PRICE * MAX_PRICE_FACTOR)\n",
        "    return df_batch\n",
        "\n",
        "def calculate_demand(row):\n",
        "    \"\"\"\n",
        "    Calculates a demand score based on various features. Used in Model 2.\n",
        "\n",
        "    Args:\n",
        "        row (pd.Series): A single row of parking data.\n",
        "\n",
        "    Returns:\n",
        "        float: The calculated demand score.\n",
        "    \"\"\"\n",
        "    # Ensure all required columns are present before calculation\n",
        "    required_cols = ['Occupancy', 'Capacity', 'Queue length', 'Nearby traffic congestion level',\n",
        "                     'Special day indicator', 'Type of incoming vehicle']\n",
        "    for col in required_cols:\n",
        "        if col not in row.index:\n",
        "            # Handle missing columns gracefully, e.g., by assigning a default value or skipping\n",
        "            print(f\"Warning: Column '{col}' not found in row. Using default value 0 for demand calculation.\")\n",
        "            if col in ['Occupancy', 'Queue length', 'Nearby traffic congestion level']:\n",
        "                row[col] = 0\n",
        "            elif col == 'Capacity':\n",
        "                row[col] = 1 # Avoid division by zero\n",
        "            elif col == 'Special day indicator':\n",
        "                row[col] = 0\n",
        "            elif col == 'Type of incoming vehicle':\n",
        "                row[col] = 'car' # Default to 'car'\n",
        "\n",
        "    occupancy_rate = row['Occupancy'] / row['Capacity']\n",
        "    # Normalize queue length and traffic using tanh for smoother scaling\n",
        "    queue_length_normalized = np.tanh(row['Queue length'] / 10.0) # Assuming max queue length around 10-20\n",
        "    traffic_normalized = np.tanh(row['Nearby traffic congestion level'] / 5.0) # Assuming traffic on a scale, e.g., 0-5\n",
        "\n",
        "    # Convert 'Special day indicator' to a numeric value (0 or 1)\n",
        "    is_special_day = 1 if str(row['Special day indicator']).lower() in ['yes', '1', 'true'] else 0\n",
        "\n",
        "    # Assign weight based on vehicle type\n",
        "    vehicle_type_weight = 0\n",
        "    vehicle_type = str(row['Type of incoming vehicle']).lower()\n",
        "    if vehicle_type == 'car':\n",
        "        vehicle_type_weight = WEIGHT_VEHICLE_TYPE_CAR\n",
        "    elif vehicle_type == 'bike':\n",
        "        vehicle_type_weight = WEIGHT_VEHICLE_TYPE_BIKE\n",
        "    elif vehicle_type == 'truck':\n",
        "        vehicle_type_weight = WEIGHT_VEHICLE_TYPE_TRUCK\n",
        "    # Add 'cycle' as a vehicle type if it exists in the dataset\n",
        "    elif vehicle_type == 'cycle':\n",
        "        vehicle_type_weight = WEIGHT_VEHICLE_TYPE_BIKE # Treating cycles like bikes for now, adjust if needed\n",
        "\n",
        "    # Combine weighted features to get the total demand score\n",
        "    demand = (WEIGHT_OCCUPANCY_RATE * occupancy_rate +\n",
        "              WEIGHT_QUEUE_LENGTH * queue_length_normalized +\n",
        "              WEIGHT_TRAFFIC * traffic_normalized +\n",
        "              WEIGHT_SPECIAL_DAY * is_special_day +\n",
        "              vehicle_type_weight)\n",
        "    return demand\n",
        "\n",
        "def normalize_demand(demand_series):\n",
        "    \"\"\"\n",
        "    Normalizes a Pandas Series of demand values to a 0-1 range.\n",
        "\n",
        "    Args:\n",
        "        demand_series (pd.Series): A Series of demand scores.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: The normalized demand scores.\n",
        "    \"\"\"\n",
        "    min_demand = demand_series.min()\n",
        "    max_demand = demand_series.max()\n",
        "    if max_demand == min_demand:\n",
        "        # If all demand values are the same, return 0.5 to avoid division by zero\n",
        "        return pd.Series([0.5] * len(demand_series), index=demand_series.index)\n",
        "    normalized_demand = (demand_series - min_demand) / (max_demand - min_demand)\n",
        "    return normalized_demand\n",
        "\n",
        "def model2_pricing_logic(df_batch):\n",
        "    \"\"\"\n",
        "    Model 2: Demand-Based Price Function\n",
        "    Price = Base Price * (1 + lambda * NormalizedDemand)\n",
        "\n",
        "    Args:\n",
        "        df_batch (pd.DataFrame): A DataFrame containing a batch of data for parking spaces.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with 'demand', 'normalized_demand', and 'predicted_price' added.\n",
        "    \"\"\"\n",
        "    # Calculate demand for each row in the batch\n",
        "    df_batch['demand'] = df_batch.apply(calculate_demand, axis=1)\n",
        "    # Normalize the calculated demand across the current batch\n",
        "    df_batch['normalized_demand'] = normalize_demand(df_batch['demand'])\n",
        "    # Apply the demand-based pricing formula\n",
        "    df_batch['predicted_price'] = BASE_PRICE * (1 + LAMBDA_MODEL2 * df_batch['normalized_demand'])\n",
        "    # Clip prices to ensure they stay within defined bounds\n",
        "    df_batch['predicted_price'] = np.clip(df_batch['predicted_price'], BASE_PRICE * MIN_PRICE_FACTOR, BASE_PRICE * MAX_PRICE_FACTOR)\n",
        "    return df_batch\n",
        "\n",
        "def model3_pricing_logic(df_batch, all_parking_data_at_timestep):\n",
        "    \"\"\"\n",
        "    Model 3: Competitive Pricing Model\n",
        "    Factors in competitor prices based on proximity.\n",
        "\n",
        "    Args:\n",
        "        df_batch (pd.DataFrame): A DataFrame containing the current batch of data for parking spaces,\n",
        "                                 which should already have 'predicted_price' from Model 2.\n",
        "        all_parking_data_at_timestep (pd.DataFrame): A DataFrame containing data (including prices and locations)\n",
        "                                                     for ALL parking spaces at the current time step.\n",
        "                                                     This is crucial for competitive analysis.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with 'competitive_factor' and adjusted 'predicted_price' added.\n",
        "    \"\"\"\n",
        "    df_batch['competitive_factor'] = 0.0 # Initialize competitive factor\n",
        "\n",
        "    for index, row in df_batch.iterrows():\n",
        "        # Ensure Latitude and Longitude exist\n",
        "        if 'Latitude' not in row or 'Longitude' not in row:\n",
        "            print(f\"Warning: Latitude or Longitude missing for Parking Space ID {row.get('Parking Space ID', 'Unknown')}. Skipping competitive pricing for this entry.\")\n",
        "            continue\n",
        "\n",
        "        current_lat = row['Latitude']\n",
        "        current_lon = row['Longitude']\n",
        "        current_parking_id = row['Parking Space ID']\n",
        "\n",
        "        nearby_competitors_prices = []\n",
        "        # Iterate through all parking spaces at this time step to find competitors\n",
        "        for _, comp_row in all_parking_data_at_timestep.iterrows():\n",
        "            if comp_row['Parking Space ID'] != current_parking_id: # Don't compare with self\n",
        "                # Ensure Latitude and Longitude exist for competitor\n",
        "                if 'Latitude' not in comp_row or 'Longitude' not in comp_row:\n",
        "                    continue # Skip this competitor if location data is missing\n",
        "\n",
        "                comp_lat = comp_row['Latitude']\n",
        "                comp_lon = comp_row['Longitude']\n",
        "                distance = calculate_distance(current_lat, current_lon, comp_lat, comp_lon)\n",
        "\n",
        "                # Consider competitors within a certain radius (e.g., 1 kilometer)\n",
        "                if distance < 1.0: # This radius can be tuned\n",
        "                    # Ensure competitor has a predicted price (from Model 2 or previous step)\n",
        "                    if 'predicted_price' in comp_row:\n",
        "                        nearby_competitors_prices.append(comp_row['predicted_price'])\n",
        "\n",
        "        if nearby_competitors_prices:\n",
        "            avg_competitor_price = np.mean(nearby_competitors_prices)\n",
        "            current_occupancy_rate = row['Occupancy'] / row['Capacity']\n",
        "\n",
        "            # Simple competitive logic:\n",
        "            # 1. If our lot is highly occupied (e.g., >90%) AND nearby competitors are cheaper,\n",
        "            #    consider slightly reducing our price to encourage flow or avoid overpricing.\n",
        "            if current_occupancy_rate > 0.9 and avg_competitor_price < row['predicted_price']:\n",
        "                df_batch.loc[index, 'competitive_factor'] = -0.05 # Reduce price by 5%\n",
        "            # 2. If nearby competitors are significantly more expensive (e.g., 10% higher),\n",
        "            #    we can slightly increase our price while remaining attractive.\n",
        "            elif avg_competitor_price > row['predicted_price'] * 1.1:\n",
        "                df_batch.loc[index, 'competitive_factor'] = 0.03 # Increase price by 3%\n",
        "\n",
        "    # Apply the competitive factor to the predicted price\n",
        "    df_batch['predicted_price'] = df_batch['predicted_price'] * (1 + df_batch['competitive_factor'])\n",
        "    # Clip prices again after competitive adjustment\n",
        "    df_batch['predicted_price'] = np.clip(df_batch['predicted_price'], BASE_PRICE * MIN_PRICE_FACTOR, BASE_PRICE * MAX_PRICE_FACTOR)\n",
        "    return df_batch\n",
        "\n",
        "def apply_pricing_model(df_batch, current_model_choice, all_parking_data_at_timestep):\n",
        "    \"\"\"\n",
        "    Applies the chosen pricing model to a batch of incoming data.\n",
        "\n",
        "    Args:\n",
        "        df_batch (pd.DataFrame): The current batch of streaming data.\n",
        "        current_model_choice (int): The ID of the model to use (1, 2, or 3).\n",
        "        all_parking_data_at_timestep (pd.DataFrame): Snapshot of all parking data at the current time step.\n",
        "                                                     Required for Model 3.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with 'predicted_price' based on the chosen model.\n",
        "    \"\"\"\n",
        "    if current_model_choice == 1:\n",
        "        return model1_pricing_logic(df_batch.copy())\n",
        "    elif current_model_choice == 2:\n",
        "        return model2_pricing_logic(df_batch.copy())\n",
        "    elif current_model_choice == 3:\n",
        "        # For Model 3, first apply Model 2 to get a base price, then apply competitive logic\n",
        "        df_with_model2_prices = model2_pricing_logic(df_batch.copy())\n",
        "        return model3_pricing_logic(df_with_model2_prices, all_parking_data_at_timestep)\n",
        "    else:\n",
        "        # Default to base price if no valid model is chosen\n",
        "        df_batch['predicted_price'] = BASE_PRICE\n",
        "        return df_batch\n",
        "\n",
        "# --- 4. Real-time Simulation Loop with Bokeh Visualization ---\n",
        "\n",
        "def run_simulation(data_path, selected_model):\n",
        "    \"\"\"\n",
        "    Simulates real-time data streaming and applies the dynamic pricing model,\n",
        "    visualizing results with Bokeh.\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the dataset CSV file.\n",
        "        selected_model (int): The pricing model to use (1, 2, or 3).\n",
        "    \"\"\"\n",
        "    print(f\"Starting simulation for Model {selected_model}...\")\n",
        "\n",
        "    # Load the entire dataset. We will simulate streaming by processing it time-step by time-step.\n",
        "    full_data = pd.read_csv(data_path)\n",
        "\n",
        "    # --- Robust Column Name Handling ---\n",
        "    # Define a mapping from potential CSV column names to expected column names in the code\n",
        "    column_name_mapping = {\n",
        "        'id': 'Parking Space ID',\n",
        "        'systemcodenumber': 'Parking Space ID', # Assuming SystemCodeNumber can also serve as ID if 'ID' is missing\n",
        "        'lastupdateddate': 'Date',\n",
        "        'lastupdatedtime': 'Time', # Will be combined with Date or used to infer Time Point\n",
        "        'vehicletype': 'Type of incoming vehicle',\n",
        "        'trafficconditionnearby': 'Nearby traffic congestion level',\n",
        "        'queuelength': 'Queue length',\n",
        "        'isspecialday': 'Special day indicator',\n",
        "        'capacity': 'Capacity',\n",
        "        'occupancy': 'Occupancy',\n",
        "        'latitude': 'Latitude',\n",
        "        'longitude': 'Longitude'\n",
        "    }\n",
        "\n",
        "    # Standardize column names\n",
        "    current_columns = {col.lower(): col for col in full_data.columns}\n",
        "    for old_name_lower, new_name in column_name_mapping.items():\n",
        "        if new_name not in full_data.columns: # Only rename if the target column name doesn't already exist\n",
        "            if old_name_lower in current_columns:\n",
        "                original_col_name = current_columns[old_name_lower]\n",
        "                full_data.rename(columns={original_col_name: new_name}, inplace=True)\n",
        "                print(f\"Renamed column '{original_col_name}' to '{new_name}'.\")\n",
        "\n",
        "    # Final check for critical columns after renaming\n",
        "    critical_columns = ['Parking Space ID', 'Capacity', 'Occupancy', 'Latitude', 'Longitude',\n",
        "                        'Type of incoming vehicle', 'Nearby traffic congestion level', 'Queue length',\n",
        "                        'Special day indicator'] # Corrected: 'TrafficConditionNearby' to 'Nearby traffic congestion level'\n",
        "    for col in critical_columns:\n",
        "        if col not in full_data.columns:\n",
        "            print(f\"Error: Critical column '{col}' not found in the dataset after renaming attempts. Available columns: {full_data.columns.tolist()}\")\n",
        "            raise KeyError(f\"Critical column '{col}' is missing or named differently in dataset.csv. Please ensure it exists.\")\n",
        "\n",
        "\n",
        "    # Ensure 'Time Point' is correctly identified for plotting\n",
        "    # If 'Time Point' column is missing, create it based on cumulative count per parking space.\n",
        "    # If 'Time' (LastUpdatedTime) exists, combine with 'Date' to create a proper datetime for sorting.\n",
        "    if 'Time Point' not in full_data.columns:\n",
        "        print(\"Warning: 'Time Point' column not found.\")\n",
        "        if 'Date' in full_data.columns and 'Time' in full_data.columns:\n",
        "            print(\"Combining 'Date' and 'Time' to create a full timestamp for sorting.\")\n",
        "            # Combine 'Date' and 'Time' into a single datetime column for accurate sorting\n",
        "            full_data['FullTimestamp'] = pd.to_datetime(full_data['Date'] + ' ' + full_data['Time'], errors='coerce', dayfirst=True)\n",
        "            full_data.sort_values(by=['Parking Space ID', 'FullTimestamp'], inplace=True)\n",
        "            full_data.dropna(subset=['FullTimestamp'], inplace=True)\n",
        "            # Create 'Time Point' as a sequential integer for plotting within each parking space's daily data\n",
        "            full_data['Time Point'] = full_data.groupby(['Parking Space ID', full_data['FullTimestamp'].dt.date]).cumcount() + 1\n",
        "        else:\n",
        "            print(\"Generating 'Time Point' based on cumulative count per parking space (less precise without full timestamp).\")\n",
        "            full_data['Time Point'] = full_data.groupby('Parking Space ID').cumcount() + 1\n",
        "    else:\n",
        "        # Ensure 'Time Point' is numeric, if it exists\n",
        "        full_data['Time Point'] = pd.to_numeric(full_data['Time Point'], errors='coerce')\n",
        "        full_data.dropna(subset=['Time Point'], inplace=True) # Drop rows where Time Point couldn't be converted\n",
        "\n",
        "    # Convert 'Date' column to datetime objects if it exists after renaming\n",
        "    if 'Date' in full_data.columns:\n",
        "        full_data['Date'] = pd.to_datetime(full_data['Date'], errors='coerce', dayfirst=True) # Use dayfirst for DD-MM-YYYY format\n",
        "        full_data.dropna(subset=['Date'], inplace=True) # Drop rows where Date couldn't be converted\n",
        "\n",
        "\n",
        "    # Get unique parking space IDs for setting up Bokeh plots\n",
        "    parking_space_ids = sorted(full_data['Parking Space ID'].unique())\n",
        "\n",
        "    # Initialize previous_price for all parking spaces for Model 1's state management.\n",
        "    # This dictionary will hold the last predicted price for each parking space.\n",
        "    parking_space_state = {pid: {'previous_price': BASE_PRICE} for pid in parking_space_ids}\n",
        "\n",
        "    # --- Bokeh Visualization Setup ---\n",
        "    output_notebook() # Directs Bokeh to render plots in the Jupyter/Colab notebook output\n",
        "\n",
        "    # Create the main Bokeh figure\n",
        "    p = figure(\n",
        "        x_axis_label=\"Time Point (Simulated)\",\n",
        "        y_axis_label=\"Predicted Price ($)\",\n",
        "        title=f\"Real-time Parking Price Prediction (Model {selected_model})\",\n",
        "        height=500,\n",
        "        width=900,\n",
        "        x_range=(0, full_data['Time Point'].max() + 1), # X-axis range based on max time point\n",
        "        y_range=(BASE_PRICE * MIN_PRICE_FACTOR * 0.9, BASE_PRICE * MAX_PRICE_FACTOR * 1.1) # Y-axis with buffer\n",
        "    )\n",
        "\n",
        "    # Dictionary to hold ColumnDataSource for each parking space.\n",
        "    # Each line on the plot will have its own data source.\n",
        "    parking_sources = {}\n",
        "    # Define a color palette for the lines\n",
        "    colors = [\"#e6194b\", \"#3cb44b\", \"#ffe119\", \"#4363d8\", \"#f58231\", \"#911eb4\", \"#46f0f0\", \"#f032e6\",\n",
        "              \"#bcf60c\", \"#fabebe\", \"#008080\", \"#e6beff\", \"#9a6324\", \"#fffac8\"]\n",
        "\n",
        "    # Initialize a line glyph and ColumnDataSource for each parking space\n",
        "    for i, pid in enumerate(parking_space_ids):\n",
        "        parking_sources[pid] = ColumnDataSource(data={'time': [], 'price': []})\n",
        "        p.line(\n",
        "            x='time', y='price',\n",
        "            legend_label=f\"Parking {pid}\",\n",
        "            line_width=2,\n",
        "            color=colors[i % len(colors)], # Assign a color from the palette\n",
        "            source=parking_sources[pid] # Link the line to its specific data source\n",
        "        )\n",
        "\n",
        "    p.legend.location = \"top_left\"\n",
        "    p.legend.click_policy=\"hide\" # Allows users to hide/show individual lines by clicking their legend entry\n",
        "\n",
        "    # Show the plot initially to get the handle for updates\n",
        "    # `notebook_handle=True` is crucial for `push_notebook` to work\n",
        "    handle = show(p, notebook_handle=True)\n",
        "\n",
        "    # --- Simulate Streaming Data and Update Plot ---\n",
        "    # Determine how to iterate through data: by 'Date' and 'Time Point' or just 'Time Point'\n",
        "    if 'Date' in full_data.columns and 'FullTimestamp' in full_data.columns:\n",
        "        # Sort by full timestamp to ensure correct chronological order across all parking spaces\n",
        "        full_data.sort_values(by='FullTimestamp', inplace=True)\n",
        "        # Iterate through unique timestamps to process all parking spaces at that moment\n",
        "        unique_timestamps = sorted(full_data['FullTimestamp'].unique())\n",
        "        time_iteration_column = 'FullTimestamp'\n",
        "    else:\n",
        "        # Fallback to 'Time Point' if full timestamp isn't available or preferred for iteration\n",
        "        full_data.sort_values(by=['Parking Space ID', 'Time Point'], inplace=True)\n",
        "        unique_timestamps = sorted(full_data['Time Point'].unique())\n",
        "        time_iteration_column = 'Time Point'\n",
        "\n",
        "\n",
        "    for current_timestamp_value in unique_timestamps:\n",
        "        current_time_data = full_data[full_data[time_iteration_column] == current_timestamp_value].copy()\n",
        "\n",
        "        # For Model 1, update the 'previous_price' column in the current batch\n",
        "        # based on the state from the previous time step.\n",
        "        if selected_model == 1:\n",
        "            for pid in current_time_data['Parking Space ID'].unique():\n",
        "                current_time_data.loc[current_time_data['Parking Space ID'] == pid, 'previous_price'] = \\\n",
        "                    parking_space_state[pid]['previous_price']\n",
        "\n",
        "        # Apply the selected pricing model to the current batch of data.\n",
        "        # For Model 3, pass the entire `current_time_data` as `all_parking_data_at_timestep`\n",
        "        # to allow competitive analysis across all parking spaces at this moment.\n",
        "        processed_data = apply_pricing_model(current_time_data, selected_model, current_time_data.copy())\n",
        "\n",
        "        # Update the state (previous price) for Model 1 for the next iteration\n",
        "        if selected_model == 1:\n",
        "            for pid in processed_data['Parking Space ID'].unique():\n",
        "                # Ensure the parking space exists in the processed data before updating state\n",
        "                if not processed_data[processed_data['Parking Space ID'] == pid].empty:\n",
        "                    parking_space_state[pid]['previous_price'] = \\\n",
        "                        processed_data.loc[processed_data['Parking Space ID'] == pid, 'predicted_price'].iloc[0]\n",
        "\n",
        "        # Update Bokeh ColumnDataSource for each parking space\n",
        "        for pid in parking_space_ids:\n",
        "            # Get the row corresponding to the current parking space at the current time point\n",
        "            parking_row = processed_data[processed_data['Parking Space ID'] == pid]\n",
        "            if not parking_row.empty:\n",
        "                # Use 'Time Point' for plotting X-axis regardless of internal iteration method\n",
        "                new_time = [parking_row['Time Point'].iloc[0]]\n",
        "                new_price = [parking_row['predicted_price'].iloc[0]]\n",
        "                # Stream the new data point to the respective ColumnDataSource\n",
        "                parking_sources[pid].stream({'time': new_time, 'price': new_price})\n",
        "\n",
        "        # Push the updated plot to the notebook output\n",
        "        push_notebook(handle=handle)\n",
        "        time.sleep(0.05) # Simulate a small delay for real-time effect (adjust as needed)\n",
        "\n",
        "    print(f\"\\nSimulation for Model {selected_model} completed for all data points.\")\n",
        "    print(\"Final predicted prices for the last time point:\")\n",
        "    # Display the final predicted prices for all parking spaces from the last processed batch\n",
        "    print(processed_data[['Parking Space ID', 'predicted_price']])\n",
        "\n",
        "# --- 5. Conceptual Pathway Integration (for reference) ---\n",
        "# This section outlines how Pathway would be used for a true real-time application.\n",
        "# The runnable code above simulates this behavior using Pandas and Bokeh directly.\n",
        "\n",
        "# @pw.udf\n",
        "# def pathway_model1_udf(row, state):\n",
        "#     # This UDF would be applied to each incoming row in a Pathway stream.\n",
        "#     # 'state' would manage the 'previous_price' for each parking space.\n",
        "#     # This is a highly simplified representation.\n",
        "#     occupancy_rate = row.Occupancy / row.Capacity\n",
        "#     previous_price = state.get('price', BASE_PRICE) # Get previous price from state\n",
        "#     predicted_price = previous_price + ALPHA_MODEL1 * occupancy_rate\n",
        "#     predicted_price = np.clip(predicted_price, BASE_PRICE * MIN_PRICE_FACTOR, BASE_PRICE * MAX_PRICE_FACTOR)\n",
        "#     state['price'] = predicted_price # Update state for next iteration\n",
        "#     return {'Parking Space ID': row['Parking Space ID'], 'predicted_price': predicted_price, 'time_point': row['Time Point']}\n",
        "\n",
        "# def run_pathway_app(data_path, selected_model):\n",
        "#     # Initialize Pathway context\n",
        "#     # pw.set_debug_mode(True) # Optional: for debugging Pathway tables\n",
        "\n",
        "#     # 1. Data Ingestion: Read CSV as a streaming table\n",
        "#     # This simulates new data arriving over time.\n",
        "#     input_stream = pw.io.csv.read(\n",
        "#         data_path,\n",
        "#         schema=None, # Pathway can infer schema\n",
        "#         mode=\"streaming\",\n",
        "#         autocommit_duration_ms=100 # Simulate small batches arriving every 100ms\n",
        "#     )\n",
        "\n",
        "#     # 2. Feature Engineering and Model Application\n",
        "#     # For Model 1 (stateful):\n",
        "#     if selected_model == 1:\n",
        "#         # Use a stateful transform to carry 'previous_price' for each parking space.\n",
        "#         # This would involve `pw.state.min_state` or a custom stateful UDF.\n",
        "#         # Example (conceptual, requires proper state management in UDF):\n",
        "#         # predicted_prices = input_stream.group_by(input_stream.Parking_Space_ID).map(\n",
        "#         #     lambda row, state: pathway_model1_udf(row, state)\n",
        "#         # )\n",
        "#         pass # Placeholder for actual Pathway stateful logic\n",
        "\n",
        "#     # For Model 2 (stateless per row, but needs batch-level normalization):\n",
        "#     elif selected_model == 2:\n",
        "#         # This would involve `pw.map` for `calculate_demand`\n",
        "#         # and then a `pw.reduce` or another `pw.map` with a global view for `normalize_demand`.\n",
        "#         # This is more complex in Pathway than a simple row-wise map.\n",
        "#         pass # Placeholder for actual Pathway logic\n",
        "\n",
        "#     # For Model 3 (needs joins for competitive data):\n",
        "#     elif selected_model == 3:\n",
        "#         # This would involve joining the input_stream with itself or another table\n",
        "#         # representing the current state of all parking lots, based on proximity.\n",
        "#         pass # Placeholder for actual Pathway join logic\n",
        "\n",
        "#     # 3. Output and Visualization\n",
        "#     # Output the predicted prices to a file or a visualization sink.\n",
        "#     # For Bokeh, Pathway has `pw.io.bokeh.write` but it usually requires a running Bokeh server.\n",
        "#     # predicted_prices.write(pw.io.csv.write(\"predicted_prices_pathway.csv\"))\n",
        "\n",
        "#     # Start the Pathway data processing engine (this is blocking)\n",
        "#     # pw.run()\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the path to your dataset.csv file\n",
        "    # Make sure this file is uploaded to your Colab environment or accessible.\n",
        "    DATASET_PATH = 'dataset.csv'\n",
        "\n",
        "    # Choose which model to run (1, 2, or 3)\n",
        "    # model_to_run = 1 # Uncomment to run Model 1\n",
        "    # model_to_run = 2 # Uncomment to run Model 2\n",
        "    model_to_run = 3 # Uncomment to run Model 3 (Recommended for full features)\n",
        "\n",
        "    run_simulation(DATASET_PATH, model_to_run)\n",
        "\n",
        "    # You can also conceptually call the Pathway function here if you had a complete Pathway setup:\n",
        "    # print(\"\\nConceptual Pathway execution (requires full Pathway setup and specific UDFs):\")\n",
        "    # run_pathway_app(DATASET_PATH, model_to_run)\n"
      ],
      "metadata": {
        "id": "4mpf6YgW2cIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}